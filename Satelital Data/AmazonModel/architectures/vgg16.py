# -*- coding: utf-8 -*-
"""VGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pC9Obveq5stS5L0utmdO5Dxl9f-wEI0B
"""

import tensorflow as tf
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras import applications

class MyModel(tf.keras.Model):

    def __init__(self, n_outputs=7, pretrained=False, freeze=False, size = 256, depth = 3):
        
        super(MyModel, self).__init__()
        
        
        if pretrained:
            self.model_weights = 'imagenet'
        else:
            self.model_weights = None
        
        # Download the architecture of VGG16 with ImageNet weights
        self.vgg = applications.VGG16(include_top=False, weights=self.model_weights, input_shape= (width,width, depth))
        
        # Taking the output of the last convolution block in VGG16
        self.res_out = self.vgg.output
        self.res_in = self.vgg.input
        
        self.conv2d = Conv2D(1024, 3, padding='same', activation='relu')
        self.GlobPoll = GlobalAveragePooling2D()
        #self.drop = Dropout(0.2)
                       
        # Adding a fully connected layer having 1024 neurons
        self.fc1 = Dense(1024, activation='relu')
        self.fc2 = Dense(512, activation='relu')
        #self.flatten = Flatten()
        
        # Sigmoid Out
        self.out = Dense(outs, activation='sigmoid')
        
        if freeze:
            # Training only top layers i.e. the layers which we have added in the end
            self.vgg.trainable = False

    def call(self, inputs, training=False):

        x = self.vgg(inputs)
        x = self.conv2d(x)
        x = self.GlobPoll(x)
        #if training:
        #    x = self.drop(x, training=training)
        #x = self.flatten(x)
        x = self.fc1(x)
        x = self.fc2(x)
        x = self.out(x)
        
        return x

